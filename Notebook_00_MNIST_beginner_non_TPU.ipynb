{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_MNIST_beginner_non_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3TACv5Y4Yj6"
      },
      "source": [
        "아래의 code는 colab TPU MNIST model에서 필요한 부분만 가져온 것이다.\n",
        "이는 이전 session 에서 정의된 MNIST model 에서 단순히 network의 크기만 늘린것이다.\n",
        "\n",
        "Network를 deep하게 가져가는 이유는 단순히 TPU가 얼마나 빠른지 test하기 목적 밖에 없다.\n",
        "\n",
        "따라서 아래의 code를 \"None\" mode 와 \"GPU\" mode 에서 실행 시켜 보기 바란다.\n",
        "속도의 차이가 어느 정도 나는지 check 해 보자.\n",
        "\n",
        "그리고 이결과를 TPU 의 계산속도와 비교해 보자.\n",
        "\n",
        "아래의 예제 code에서는 for 문을 time 을 가지고 제어하지는 않는다.\n",
        "아직은 복잡한 문제가 아니기 때문에 time을 가지고 제어하는 것은 향후 복잡한 문제에 들어갈때 몇가지 예제를 만들 예정인다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5h2QDQb4ZVJ",
        "outputId": "b0accae9-fa57-4d41-fb4c-6c9e3eb657f5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Activation('elu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    x_train.astype(np.float32), y_train.astype(np.float32),\n",
        "    epochs=17,\n",
        "    steps_per_epoch=60,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=17\n",
        ")\n",
        "\n",
        "model.save_weights('./fashion_mnist.h5', overwrite=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/17\n",
            " 2/60 [>.............................] - ETA: 1s - loss: 5.4717 - sparse_categorical_accuracy: 0.1665WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0093s vs `on_train_batch_end` time: 0.0536s). Check your callbacks.\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 1.2366 - sparse_categorical_accuracy: 0.6655\n",
            "Epoch 2/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.8135\n",
            "Epoch 3/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.4485 - sparse_categorical_accuracy: 0.8448\n",
            "Epoch 4/17\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 0.3850 - sparse_categorical_accuracy: 0.8659\n",
            "Epoch 5/17\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 0.3477 - sparse_categorical_accuracy: 0.8778\n",
            "Epoch 6/17\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 0.3204 - sparse_categorical_accuracy: 0.8880\n",
            "Epoch 7/17\n",
            "60/60 [==============================] - 4s 60ms/step - loss: 0.2897 - sparse_categorical_accuracy: 0.8962\n",
            "Epoch 8/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9034\n",
            "Epoch 9/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.2494 - sparse_categorical_accuracy: 0.9095\n",
            "Epoch 10/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.2360 - sparse_categorical_accuracy: 0.9143\n",
            "Epoch 11/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.2184 - sparse_categorical_accuracy: 0.9204\n",
            "Epoch 12/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.2064 - sparse_categorical_accuracy: 0.9241\n",
            "Epoch 13/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.1971 - sparse_categorical_accuracy: 0.9262\n",
            "Epoch 14/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.1872 - sparse_categorical_accuracy: 0.9296\n",
            "Epoch 15/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.1743 - sparse_categorical_accuracy: 0.9358\n",
            "Epoch 16/17\n",
            "60/60 [==============================] - 4s 59ms/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9366\n",
            "Epoch 17/17\n",
            "60/60 [==============================] - 5s 75ms/step - loss: 0.1599 - sparse_categorical_accuracy: 0.9403 - val_loss: 0.2231 - val_sparse_categorical_accuracy: 0.9250\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
